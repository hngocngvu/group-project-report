In this work, we presented an end-to-end pipeline for automatic Japanese manga translation, integrating speech bubble segmentation, optical character recognition, machine translation, and typesetting into a unified Qt-based desktop application. Our system leverages YOLOv8 for bubble and panel segmentation, MangaOCR for Japanese text recognition with post-processing, and Qwen2.5-1.5B-Instruct fine-tuned with LoRA for context-aware translation. Rather than replacing human translators, the application aims to reduce repetitive manual effort while providing editing functionality at each stage of the workflow.

Future work includes improving OCR accuracy through expanded training data and enhanced post-processing techniques, developing more sophisticated context-aware translation that better captures conversation history and speaker identity across dialogue sequences, and refining the application interface to provide a more intuitive experience with additional features tailored to professional translator workflows.