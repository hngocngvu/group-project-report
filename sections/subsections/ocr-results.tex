To evaluate the OCR module, we tested the model on a subset of 640 speech bubbles using Character Error Rate (CER) and Word Error Rate (WER). As shown in Table~\ref{tab:ocr_results}, the raw model output yielded a CER of 0.1628. However, applying our deterministic post-processing pipeline significantly improved performance, ultimately reducing the CER to 0.1226 and WER to 0.4609.

The step-wise breakdown reveals that \textbf{Unicode Normalization} provided the largest single gain (reducing CER by $\approx$ 2.2\%) by correcting the model's tendency to generate full-width alphanumeric characters. Subsequently, \textbf{Punctuation Standardization} further reduced error rates by unifying inconsistent ellipsis styles, confirming that a significant portion of raw errors were formatting artifacts rather than recognition failures.

\begin{table}[H]
\centering
\caption{Impact of post-processing operations on OCR performance}
\label{tab:ocr_results}

\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.3}

\begin{tabular}{cccc}
\toprule
\textbf{Step} & \textbf{Operation} & \textbf{CER} & \textbf{WER} \\
\midrule
0 & Raw Output & 0.1628 & 0.5984 \\
1 & Unicode Normalize & 0.1408 & 0.4984 \\
2 & Whitespace Removal & 0.1408 & 0.4984 \\
3 & Ellipsis Fixing & 0.1231 & 0.4625 \\
4 & \textbf{Final Pipeline} & \textbf{0.1226} & \textbf{0.4609} \\
\bottomrule
\end{tabular}
\end{table}