Manga translation is a multimodal task that requires the integration of visual understanding and natural language processing, as textual content is tightly coupled with visual layouts, speech bubbles, and artistic styles. Unlike standard document translation, manga translation involves complex page structures, non-linear reading orders, and text embedded within illustrations, posing significant challenges for full automation.
To support manual manga translation, we present an end-to-end pipeline designed to assist translators by decomposing the workflow into four main stages: speech bubble segmentation, optical character recognition (OCR), machine translation, and typesetting. Rather than replacing human translators, our system aims to reduce repetitive manual effort.
A Qt-based application is developed to provide an interactive interface, enabling users to load manga pages and visualize translated outputs in a unified environment.
All processing stages are executed automatically in the background, allowing translators to focus on translation refinement.