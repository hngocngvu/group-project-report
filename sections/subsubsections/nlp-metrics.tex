For OCR evaluation, we use Character Error Rate (CER) and Word Error Rate (WER) as the primary metrics.

\begin{enumerate}
    \item \textbf{Character Error Rate (CER)}

    CER is derived as the Levenshtein distance from the predicted text and the reference text divided by total number of characters in the reference text, the metric is formulated as follow:

    \begin{equation}
        CER = \frac{S + D + I}{N}
    \end{equation}

    Where:
    \begin{itemize}
        \item S (Substitution): the number of characters incorrectly recognized as different characters
        \item D (Deletion): the number of characters present in the reference but missing in the prediction
        \item I (Insertion): the number of extra characters present in the prediction but not in the reference
        \item N: the \textbf{total number of characters} in the reference text
    \end{itemize}

    \item \textbf{Word Error Rate (WER)}

    WER is widely used to evaluate the accuracy of transcription systems. It is derived as the Levenshtein distance from the predicted text and the reference text divided by total number of words in the reference text, the metric is formulated as follow:

    \begin{equation}
        WER = \frac{S + D + I}{N}
    \end{equation}

    Where:
    \begin{itemize}
        \item S (Substitution): the number of words incorrectly recognized as different words
        \item D (Deletion): the number of words present in the reference but missing in the prediction
        \item I (Insertion): the number of extra words present in the prediction but not in the reference
        \item N: the \textbf{total number of words} in the reference text
    \end{itemize}
\end{enumerate}


