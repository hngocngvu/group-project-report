The raw output generated by the OCR model often contains artifacts inherent to stochastic decoding, such as irregular whitespace and inconsistent character encodings. To ensure high-quality input for the subsequent translation module, we implemented a deterministic cleaning pipeline utilizing regular expressions and Unicode normalization.

The process applies the following transformations sequentially:
\begin{enumerate}
\item \textbf{Unicode Normalization (NFKC):} Standardizes character widths by converting full-width alphanumeric characters (e.g., \begin{CJK}{UTF8}{min}１ Ａ\end{CJK}) into their canonical half-width counterparts (``1'', ``A'').
\item \textbf{Whitespace Removal:} Eliminates phantom spaces inserted between characters, as Japanese writing does not rely on whitespace for word delimitation.
\item \textbf{Punctuation Standardization:}
Collapses sequences of multiple periods into a single ellipsis (...) and
normalizes tildes (\textasciitilde) to the Japanese wave dash (U+301C) to maintain typographic consistency.
\end{enumerate}

The impact of this pipeline is demonstrated in Table \ref{tab:ocr_cleaning}.

\begin{table}[H]
\centering
\caption{Comparison of Raw OCR outputs against Post-processed text and Ground Truth.}
\label{tab:ocr_cleaning}

\setlength{\tabcolsep}{8pt}
\renewcommand{\arraystretch}{1.3}

\begin{CJK}{UTF8}{min}
\begin{tabular}{>{\raggedright\arraybackslash}p{0.3\textwidth}
                >{\raggedright\arraybackslash}p{0.3\textwidth}
                >{\raggedright\arraybackslash}p{0.3\textwidth}}
\toprule
\rowcolor[HTML]{EFEFEF}
\textbf{Ground Truth} & \textbf{Raw OCR Output} & \textbf{Post-processed Text} \\
\midrule
爆発まで残り 04:30:21 &
爆発まで残り、　Ｄ４：３０：２１ &
爆発まで残り、D4:30:21 \\

なっななな\ldots 何やってんの!? &
なっななな\ldots 何やってんの！？ &
なっななな\ldots 何やってんの!? \\

うへ\textasciitilde\textasciitilde!? なんじゃ &
うへ \textasciitilde{} \textasciitilde{} !? なんじゃ &
うへ\textasciitilde\textasciitilde!? なんじゃ \\

ファンクラブ規約No.13 &
ファンクラブ規約 Ｎｏ．１３ &
ファンクラブ規約No.13 \\
\bottomrule
\end{tabular}
\end{CJK}
\end{table}
